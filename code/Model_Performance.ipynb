{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Splitting Data in Python**\n",
        "\n",
        "The `train_test_split()` function in pandas divides a DataFrame into two subsets as specified by the user. Parameters are outlined in scikit-learn documentation. Python employs a random number generator for creating training-testing-validation divisions. Using a seed value ensures consistent splits across code runs.  \n",
        "\n",
        "The code below does so for the bad drivers dataset using the proportions 70%/10%/20% for training, validation, and test data, respectively .\n",
        "\n"
      ],
      "metadata": {
        "id": "80U5_SQ2H8ia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9NyDyXUH2vd"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load bad drivers data\n",
        "badDrivers = pd.read_csv('bad-drivers.csv')"
      ],
      "metadata": {
        "id": "WTmIiWrcIqia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the bad drivers data\n",
        "badDrivers"
      ],
      "metadata": {
        "id": "UeY0dvblIr1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the proportions of the training-validation-test split\n",
        "trainingProportion = 0.70\n",
        "validationProportion = 0.10\n",
        "testProportion = 0.20\n",
        "\n",
        "# Split off the test data\n",
        "trainingAndValidationData, testData = train_test_split(\n",
        "    badDrivers, test_size=testProportion\n",
        ")\n",
        "\n",
        "# Split the remaining into training and validation data\n",
        "trainingData, validationData = train_test_split(\n",
        "    trainingAndValidationData,\n",
        "    train_size=trainingProportion / (trainingProportion + validationProportion),\n",
        ")"
      ],
      "metadata": {
        "id": "dB75bnXVIuLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display training data\n",
        "trainingData"
      ],
      "metadata": {
        "id": "cBpkm_mWIvx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display validation data\n",
        "validationData"
      ],
      "metadata": {
        "id": "F6TZL1rbIxjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display test data\n",
        "testData"
      ],
      "metadata": {
        "id": "ypfzpDgEIy8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the scatter plot for the entire sample data\n",
        "plt.scatter(\n",
        "    badDrivers[['Losses incurred by insurance companies for collisions per insured driver ($)']],\n",
        "    badDrivers[['Car Insurance Premiums ($)']],\n",
        ")\n",
        "plt.xlabel('Losses incurred by insurance companies', fontsize=14)\n",
        "plt.ylabel('Car insurance premiums', fontsize=14)\n",
        "plt.xlim(80, 200)\n",
        "plt.ylim(600, 1400)\n",
        "plt.title('Sample data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9rG7J2xdI0XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the scatter plot for the training data\n",
        "plt.scatter(\n",
        "    trainingData[['Losses incurred by insurance companies for collisions per insured driver ($)']],\n",
        "    trainingData[['Car Insurance Premiums ($)']],\n",
        ")\n",
        "plt.xlabel('Losses incurred by insurance companies', fontsize=14)\n",
        "plt.ylabel('Car insurance premiums', fontsize=14)\n",
        "plt.xlim(80, 200)\n",
        "plt.ylim(600, 1400)\n",
        "plt.title('Training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S1ngevlEI2aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the scatter plot for the validation data\n",
        "plt.scatter(\n",
        "    validationData[['Losses incurred by insurance companies for collisions per insured driver ($)']],\n",
        "    validationData[['Car Insurance Premiums ($)']],\n",
        ")\n",
        "plt.xlabel('Losses incurred by insurance companies', fontsize=14)\n",
        "plt.ylabel('Car insurance premiums', fontsize=14)\n",
        "plt.xlim(80, 200)\n",
        "plt.ylim(600, 1400)\n",
        "plt.title('Validation data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ed1V8_0-I4Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the scatter plot for the test data\n",
        "plt.scatter(\n",
        "    testData[['Losses incurred by insurance companies for collisions per insured driver ($)']],\n",
        "    testData[['Car Insurance Premiums ($)']],\n",
        ")\n",
        "plt.xlabel('Losses incurred by insurance companies', fontsize=14)\n",
        "plt.ylabel('Car insurance premiums', fontsize=14)\n",
        "plt.xlim(80, 200)\n",
        "plt.ylim(600, 1400)\n",
        "plt.title('Test data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hmoJwcvbI5if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loss Functions for Regression in Python**\n",
        "\n",
        "Python computes regression model errors with `mean_squared_error()` for MSE and `mean_absolute_error() `for MAE. For root mean squared error, use squared=False in `mean_squared_error()`. Details in respective function documentation.  \n",
        "\n",
        "The code below computes all four metrics for the linear and quadratic regression on the tortoise data."
      ],
      "metadata": {
        "id": "b7Q3jxwwI-AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "SCBgBHweJQ7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tortoise data\n",
        "tortoise = pd.read_csv(\"Tortoises.csv\")"
      ],
      "metadata": {
        "id": "-atdDYmVJRhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store relevant columns as variables\n",
        "X = tortoise[\"Length\"]\n",
        "y = tortoise[\"Clutch\"]"
      ],
      "metadata": {
        "id": "Pb0kqBRAJSzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=123\n",
        ")"
      ],
      "metadata": {
        "id": "JaudOitAJT6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear model using the training set and predictions using the test set\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n",
        "linModel = LinearRegression()\n",
        "linModel.fit(X_train.values.reshape(-1, 1), y_train.values.reshape(-1, 1))\n",
        "y_pred = np.ravel(linModel.predict(X_test.reshape(-1, 1)))"
      ],
      "metadata": {
        "id": "t5bC568GJV-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display linear model and scatter plot of the test set\n",
        "plt.scatter(X_test, y_test)\n",
        "plt.xlabel(\"Length (mm)\", fontsize=14)\n",
        "plt.ylabel(\"Clutch size\", fontsize=14)\n",
        "plt.plot(X_test, y_pred, color='red')\n",
        "plt.ylim([0, 14])\n",
        "for i in range(5):\n",
        "    plt.plot([X_test[i], X_test[i]], [y_test[i], y_pred[i]], color='grey', linewidth=2)"
      ],
      "metadata": {
        "id": "GAFiJDOpJXQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display MSE\n",
        "metrics.mean_squared_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Q0fAVPbpJYvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display RMSE\n",
        "metrics.mean_squared_error(y_test, y_pred, squared=False)"
      ],
      "metadata": {
        "id": "bF8HKoUBJaWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display MAE\n",
        "metrics.mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "BNUPYgKkJbqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a quadratic model using the training set and predictions using the test set\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "poly = PolynomialFeatures().fit_transform(X_train.reshape(-1, 1))\n",
        "poly_reg_model = LinearRegression().fit(poly, y_train)\n",
        "poly_test = PolynomialFeatures().fit_transform(X_test.reshape(-1, 1))\n",
        "y_pred = poly_reg_model.predict(poly_test)"
      ],
      "metadata": {
        "id": "jvQduuBHJduy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display quadratic model and scatter plot of the test set\n",
        "plt.scatter(X_test, y_test)\n",
        "plt.xlabel(\"Length (mm)\", fontsize=14)\n",
        "plt.ylabel(\"Clutch size\", fontsize=14)\n",
        "x = np.linspace(X_test.min(), X_test.max(), 100)\n",
        "y = (\n",
        "    poly_reg_model.coef_[2] * x**2\n",
        "    + poly_reg_model.coef_[1] * x\n",
        "    + poly_reg_model.intercept_\n",
        ")\n",
        "plt.plot(x, y, color='red', linewidth=2)\n",
        "plt.ylim([0, 14])\n",
        "for i in range(5):\n",
        "    plt.plot([X_test[i], X_test[i]], [y_test[i], y_pred[i]], color='grey', linewidth=2)"
      ],
      "metadata": {
        "id": "FVvbPRHlJe_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display MSE\n",
        "metrics.mean_squared_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "JgKLyyn0Jgg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display RMSE\n",
        "metrics.mean_squared_error(y_test, y_pred, squared=False)"
      ],
      "metadata": {
        "id": "wAS9QNzcJhym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display MAE\n",
        "metrics.mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "gjhuCNi5JjBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loss Functions for Classification in Python**\n",
        "\n",
        "Compute log loss with `log_loss()` from `sklearn.metrics` package. Use `y_true` and `y_pred` arrays. Find other parameters in log_loss [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html).  \n",
        "\n",
        "The code below computes the log loss for a logistic regression model on the Wisconsin breast cancer dataset."
      ],
      "metadata": {
        "id": "JWchYtw9JnvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages and functions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fPbUbja5KIHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Wisconsin Breast Cancer dataset\n",
        "WBCD = pd.read_csv('WisconsinBreastCancerDatabase.csv')"
      ],
      "metadata": {
        "id": "BpcMXRzYKJnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Diagnosis to 0 and 1\n",
        "WBCD.loc[WBCD['Diagnosis'] == 'B', 'Diagnosis'] = 0\n",
        "WBCD.loc[WBCD['Diagnosis'] == 'M', 'Diagnosis'] = 1"
      ],
      "metadata": {
        "id": "DUozB7r2KK5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store relevant columns as variables\n",
        "X = WBCD[['Radius mean']].values.reshape(-1, 1)\n",
        "y = WBCD[['Diagnosis']].values.reshape(-1, 1).astype(int)"
      ],
      "metadata": {
        "id": "hf48gtgGKMea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=123\n",
        ")"
      ],
      "metadata": {
        "id": "Yh4xDG54KN4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression predicting diagnosis from tumor radius\n",
        "logisticModel = LogisticRegression()\n",
        "logisticModel.fit(X_train, np.ravel(y_train.astype(int)))"
      ],
      "metadata": {
        "id": "NkGbyfuhKPLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph logistic regression probabilities\n",
        "plt.scatter(X_test, y_test)\n",
        "x_prob = np.linspace(X_test.min(), X_test.max(), 1000)\n",
        "y_prob = logisticModel.predict_proba(x_prob.reshape(-1, 1))[:, 1]\n",
        "plt.plot(x_prob, y_prob, color='red')\n",
        "plt.xlabel('Radius mean', fontsize=14)\n",
        "plt.ylabel('Probability of malignant tumor', fontsize=14)"
      ],
      "metadata": {
        "id": "DCUJtPfaKQkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the probabilities for the test set\n",
        "p_hat = logisticModel.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "YtRvI_SmKVOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the log-loss\n",
        "metrics.log_loss(y_test, p_hat)"
      ],
      "metadata": {
        "id": "Gh75RS0vKWtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Binary Classification Metrics in Python**\n",
        "\n",
        "\n",
        "Python computes accuracy, precision, and recall from a binary classifier using `accuracy_score()`, `precision_score()`, and `recall_score()`. Input true and predicted classifications as 0 (neg) and 1 (pos) arrays. Generate ROC curve with `roc_curve()` and `RocCurveDisplay()`.  \n",
        "\n",
        "The code below calculates metrics for logistic regression on Wisconsin breast cancer data. It also computes scores for varied cutoffs in the same regression."
      ],
      "metadata": {
        "id": "-UcXSZVdKiCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "VgajCD8xLD9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load breast cancer data and hot encodes categorical variable\n",
        "WBCD = pd.read_csv(\"WisconsinBreastCancerDatabase.csv\")\n",
        "WBCD.loc[WBCD['Diagnosis'] == 'B', 'Diagnosis'] = 0\n",
        "WBCD.loc[WBCD['Diagnosis'] == 'M', 'Diagnosis'] = 1"
      ],
      "metadata": {
        "id": "qP-mRAXLLEak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store relevant columns as variables\n",
        "X = WBCD[['Radius mean']].values.reshape(-1, 1)\n",
        "y = WBCD[['Diagnosis']].values.reshape(-1, 1).astype(int)"
      ],
      "metadata": {
        "id": "BOrWL9jZLFvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression predicting diagnosis from tumor radius\n",
        "logisticModel = LogisticRegression()\n",
        "logisticModel.fit(X, np.ravel(y.astype(int)))\n",
        "cutoff = 0.5\n",
        "yPredictedProb = logisticModel.predict_proba(X)[:, 1]\n",
        "yPredLowCutoff = []\n",
        "for i in range(0, yPredictedProb.size):\n",
        "    if yPredictedProb[i] < cutoff:\n",
        "        yPredLowCutoff.append(0)\n",
        "    else:\n",
        "        yPredLowCutoff.append(1)"
      ],
      "metadata": {
        "id": "SpaAXU0KLH3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display accuracy\n",
        "metrics.accuracy_score(y, yPredLowCutoff)"
      ],
      "metadata": {
        "id": "cyxU5NHPLJRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display precision\n",
        "metrics.precision_score(y, yPredLowCutoff)"
      ],
      "metadata": {
        "id": "Zl8EelYQLKm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display recall\n",
        "metrics.recall_score(y, yPredLowCutoff)"
      ],
      "metadata": {
        "id": "7gQ9sTw6LMGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the ROC curve\n",
        "pred = logisticModel.predict_proba(X)[:, 1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(\n",
        "    fpr=fpr, tpr=tpr, roc_auc=roc_auc, pos_label='Malignant, 1'\n",
        ")\n",
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "thvAI1yKLNcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Cross-validation in Python**\n",
        "\n",
        "`cross_val_score()` estimates model errors with k-fold cross-validation using specified folds and a metric. Default scorer depends on the model, like `r2` for `LinearModel()`. Note differences between scorer objects and functions, such as `neg_mean_square_error` vs. `mean_square_error`. Pairs like `r2` and `r2_score` match. Find scorer details in scikit-learn [docs](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).  \n",
        "\n",
        "Below, code loads bad drivers data, reserves 20% as test set, applies 10-fold cross-validation and LOOCV with mean squared error scoring. Use negative sign to fix `neg_mean_square_error`'s sign flip in `cross_val_score` calls."
      ],
      "metadata": {
        "id": "OP1vkud2LYGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages and functions\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ],
      "metadata": {
        "id": "R-oCpZGkL_zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "badDrivers = pd.read_csv('bad-drivers.csv')\n",
        "\n",
        "# Split off 20% of the data to be left out as test data\n",
        "badDriversTrainingdata, testData = train_test_split(badDrivers, test_size=0.20)\n",
        "\n",
        "# Store relevant columns as variables\n",
        "X = badDriversTrainingdata[\n",
        "    ['Losses incurred by insurance companies for collisions per insured driver ($)']\n",
        "].values.reshape(-1, 1)\n",
        "y = badDriversTrainingdata[['Car Insurance Premiums ($)']].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "LReiuqNdMCN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a linear model to the data\n",
        "linModel = LinearRegression()\n",
        "linModel.fit(X, y)\n",
        "yPredicted = linModel.predict(X)\n",
        "\n",
        "# Plot the fitted model\n",
        "plt.scatter(X, y, color='black')\n",
        "plt.plot(X, yPredicted, color='blue', linewidth=1)\n",
        "plt.xlabel('Losses incurred by insurance companies', fontsize=14)\n",
        "plt.ylabel('Car insurance premiums', fontsize=14)"
      ],
      "metadata": {
        "id": "sdAoiphKMDe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neg_mean_square_error is the negative MSE, so add a - so the scores are positive.\n",
        "ten_fold_scores = -cross_val_score(\n",
        "    linModel, X, y, scoring='neg_mean_squared_error', cv=10\n",
        ")"
      ],
      "metadata": {
        "id": "qhDvhdC1MEvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neg_mean_square_error is the negative MSE, so add a - so the scores are positive.\n",
        "LOOCV_scores = -cross_val_score(linModel, X, y, scoring='neg_mean_squared_error', cv=40)"
      ],
      "metadata": {
        "id": "Y7MPWgGCMGM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the errors for both scores\n",
        "plt.plot(np.zeros_like(ten_fold_scores), ten_fold_scores, '.')\n",
        "plt.plot(np.zeros_like(LOOCV_scores) + 1, LOOCV_scores, '.')\n",
        "plt.ylabel('Mean squared errors', fontsize=14)\n",
        "plt.xticks([0, 1], ['10-fold', 'LOOCV'])"
      ],
      "metadata": {
        "id": "xsvZJiosMHri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**The bootstrap Method in Python**\n",
        "\n",
        "`resample()` creates bootstrap sample with `replace=True` and `n_samples` as existing dataset size. Parameters in `scikit-learn` [docs](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html). Out-of-bag sample from complement of bootstrap using `~` on dataframe's indices.  \n",
        "\n",
        "\n",
        "Code fits linear model to \"bad drivers\" dataset, computes mean squared error for 30 bootstrap samples."
      ],
      "metadata": {
        "id": "jLzqpLIaMVRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages and functions\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "8lCNOk8qMu9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data set\n",
        "badDrivers = pd.read_csv('bad-drivers.csv')"
      ],
      "metadata": {
        "id": "EqYMbNoUMvdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bootstrap samples and collect errors\n",
        "\n",
        "bootstrapErrors = []\n",
        "for i in range(0, 30):\n",
        "    # Create the bootstrap sample and the out-of-bag sample\n",
        "    boot = resample(badDrivers, replace=True, n_samples=51)\n",
        "    oob = badDrivers[~badDrivers.index.isin(boot.index)]\n",
        "\n",
        "    # Fit a linear model to the bootstrap sample\n",
        "    XBoot = boot[\n",
        "        ['Losses incurred by insurance companies for collisions per insured driver ($)']\n",
        "    ].values.reshape(-1, 1)\n",
        "    yBoot = boot[['Car Insurance Premiums ($)']].values.reshape(-1, 1)\n",
        "    linModel = LinearRegression()\n",
        "    linModel.fit(XBoot, yBoot)\n",
        "\n",
        "    # Predict y values for the out-of-bag sample\n",
        "    XOob = oob[\n",
        "        ['Losses incurred by insurance companies for collisions per insured driver ($)']\n",
        "    ].values.reshape(-1, 1)\n",
        "    YOob = oob[['Car Insurance Premiums ($)']].values.reshape(-1, 1)\n",
        "    YOobPredicted = linModel.predict(XOob)\n",
        "\n",
        "    # Calculate the error\n",
        "    bootError = mean_squared_error(YOob, YOobPredicted)\n",
        "    bootstrapErrors.append(bootError)"
      ],
      "metadata": {
        "id": "F55zhqHBMw3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of the errors\n",
        "np.mean(bootstrapErrors)"
      ],
      "metadata": {
        "id": "fEqw6G-GMzm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the standard deviation of the errors\n",
        "np.std(bootstrapErrors)"
      ],
      "metadata": {
        "id": "qDuWnKAgM1BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the errors\n",
        "plt.plot(bootstrapErrors, np.zeros_like(bootstrapErrors), '.')\n",
        "plt.xlabel('Bootstrap errors (MSE)', fontsize=14)\n",
        "plt.gca().axes.yaxis.set_ticks([])"
      ],
      "metadata": {
        "id": "AtYcB7E_M2bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Selection in Python**\n",
        "\n",
        "The code below loads semiconductor data, assesses RMSE of polynomial regressions (degree 1-6) with 10-fold cross-validation, plots MSEs for model selection."
      ],
      "metadata": {
        "id": "gMt4g65KM7Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "7fF4ZQgKNF9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "thurber = pd.read_csv('Thurber.csv')\n",
        "\n",
        "# Split off 20% of the data to be left out as test data\n",
        "thurberTrainingData, test_data = train_test_split(thurber, test_size=0.20)\n",
        "\n",
        "# Store relevant columns as variables\n",
        "X = thurberTrainingData[['log(Density)']].values.reshape(-1, 1)\n",
        "y = thurberTrainingData[['Electron mobility']].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "pMJOler2NMel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a cubic regression model\n",
        "polyFeatures = PolynomialFeatures(degree=3, include_bias=False)\n",
        "XPoly = polyFeatures.fit_transform(X)\n",
        "polyModel = LinearRegression()\n",
        "polyModel.fit(XPoly, y)\n",
        "\n",
        "# Graph the scatterplot and the polynomial regression\n",
        "plt.scatter(X, y, color='black')\n",
        "xDelta = np.linspace(X.min(), X.max(), 1000)\n",
        "yDelta = polyModel.predict(polyFeatures.fit_transform(xDelta.reshape(-1, 1)))\n",
        "plt.plot(xDelta, yDelta, color='blue', linewidth=2)\n",
        "plt.xlabel('log(Density)', fontsize=14)\n",
        "plt.ylabel('Electron mobility', fontsize=14)"
      ],
      "metadata": {
        "id": "kleEatB7NN9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect cross-validation metrics\n",
        "cvMeans = []\n",
        "cvStdDev = []\n",
        "\n",
        "for i in range(1, 7):\n",
        "    # Fit a degree i polynomial regression model\n",
        "    polyFeatures = PolynomialFeatures(degree=i, include_bias=False)\n",
        "    XPoly = polyFeatures.fit_transform(X)\n",
        "    polyModel = LinearRegression()\n",
        "    polyModel.fit(XPoly, y)\n",
        "\n",
        "    # Carry out 10-fold cross-validation for the a degree i polynomial regression model\n",
        "    polyscore = -cross_val_score(\n",
        "        polyModel, XPoly, y, scoring='neg_mean_squared_error', cv=10\n",
        "    )\n",
        "\n",
        "    # Store the mean and standard deviation of the 10-fold cross-validation for the degree i polynomial regression model\n",
        "    cvMeans.append(np.mean(polyscore))\n",
        "    cvStdDev.append(np.std(polyscore))"
      ],
      "metadata": {
        "id": "lo_GTgO3NQSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph the errorbar chart using the cross-validation means and std deviations\n",
        "plt.errorbar(x=range(1, 7), y=cvMeans, yerr=cvStdDev, marker='o', color='black')\n",
        "plt.xlabel('Degree of regression polynomial', fontsize=14)\n",
        "plt.ylabel('Mean squared error', fontsize=14)"
      ],
      "metadata": {
        "id": "8K--QwO9NRvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}