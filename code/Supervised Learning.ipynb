{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3wmZyuO4DHHzodfPQLSYC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**K-nearest Neighbors Classification in Python**\n","\n","The Python code below classifies beans by the bean's major and minor axis lengths."],"metadata":{"id":"roX5x6F4FqX-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4mJ5DHIFpZV"},"outputs":[],"source":["# Import needed packages for classification\n","from sklearn.neighbors import KNeighborsClassifier\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","# Import packages for visualization of results\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from matplotlib.colors import ListedColormap\n","\n","# Iport packages for evaluation\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics"]},{"cell_type":"code","source":["# Read data, clean up names\n","\n","beans = pd.read_csv(\"https://raw.githubusercontent.com/mh2t/DS5110/main/data/Dry_Bean_Dataset.csv\")\n","beans[\"Class\"] = beans[\"Class\"].str.capitalize()\n","print(beans.shape)\n","beans.describe()"],"metadata":{"id":"Z8YZqfolF8YI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize model\n","beanKnnClassifier = KNeighborsClassifier(n_neighbors=5)\n","# Split data\n","X = beans[[\"MajorAxisLength\", \"MinorAxisLength\"]]\n","y = beans[[\"Class\"]]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"],"metadata":{"id":"ddJvQDdLF-CD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scale data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)"],"metadata":{"id":"mtcstDCGGAjf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train model and make predictions for the test set.\n","beanKnnClassifier.fit(X_train_scaled, np.ravel(y_train))\n","y_pred = beanKnnClassifier.predict(scaler.transform(X_test))"],"metadata":{"id":"7it4_IwwGB34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict one bean\n","bean = pd.DataFrame(data={\"MajorAxisLength\": [400], \"MinorAxisLength\": [200]})\n","beanKnnClassifier.predict(scaler.transform(bean))"],"metadata":{"id":"c5z8XyG1GDKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute metrics\n","print(metrics.accuracy_score(y_pred, y_test))\n","print(metrics.confusion_matrix(y_pred, y_test))"],"metadata":{"id":"K0yTqbamGEf2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Visualizing the Regions of Classification**"],"metadata":{"id":"2Bu5Ed-lGGZo"}},{"cell_type":"code","source":["# Define function for the plot.\n","#  X - two feature data frame,\n","#  y - output feature,\n","#  classifier - model that has been fit,\n","#  le - label encoder\n","#  with_data - plot the data with the regions\n","\n","\n","def plot_classification_regions(X, y, classifier, le, with_data=False):\n","\n","    # Predict class on a regular grid\n","\n","    # Plot the decision boundary. For that, we will assign a color to each\n","    # point in the mesh [x_min, x_max]x[y_min, y_max].\n","    x_min, x_max = X.iloc[:, 0].min() - 10, X.iloc[:, 0].max() + 10\n","    y_min, y_max = X.iloc[:, 1].min() - 10, X.iloc[:, 1].max() + 10\n","    xh = (x_max - x_min) / 200  # step size in the mesh for the x direction\n","    yh = (y_max - y_min) / 200  # step size in the mesh for the y direction\n","\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, xh), np.arange(y_min, y_max, yh))\n","    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","    # Get outputs ready for plotting\n","    Z = le.transform(Z)\n","    Z = Z.reshape(xx.shape)\n","    numClasses = len(le.classes_)\n","    # Plot the regions classified as different classes\n","    plt.figure(figsize=(8, 6))\n","    plt.contourf(\n","        xx,\n","        yy,\n","        Z,\n","        levels=[i - 0.5 for i in range(numClasses + 1)],\n","        cmap=ListedColormap(\n","            sns.color_palette(\"colorblind\", as_cmap=False, n_colors=numClasses)\n","        ),\n","    )\n","\n","    if with_data:\n","        p1 = sns.scatterplot(\n","            data=X,\n","            x=X.columns[0],\n","            y=X.columns[1],\n","            hue=le.transform(np.ravel(y)),\n","            palette=\"colorblind\",\n","            alpha=1,\n","            edgecolor=\"black\",\n","            style=le.transform(np.ravel(y)),\n","        )\n","        leg = p1.legend()\n","        leg.set_title(\"Variety\")\n","        for t, l in zip(leg.texts, le.inverse_transform(range(7))):\n","            t.set_text(l)"],"metadata":{"id":"EHixRRTHGK1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take a sample to keep runtime low while seeing what areas are classified as each bean\n","beanSample = beans.sample(750, random_state=20220509)\n","beanSample.describe()"],"metadata":{"id":"3EG2UREpGMgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a label encoder so colors match between plots\n","le = preprocessing.LabelEncoder()\n","le.fit(beanSample[\"Class\"])"],"metadata":{"id":"uk-_EgwQGN1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define input and output features\n","X = beanSample[[\"MajorAxisLength\", \"MinorAxisLength\"]]\n","y = beanSample[[\"Class\"]]\n","\n","# Fit model\n","beanKnnClassifier.fit(X, np.ravel(y))"],"metadata":{"id":"VRvb36FWGP2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defined in the first cell in this section\n","plot_classification_regions(X, y, beanKnnClassifier, le, with_data=False)"],"metadata":{"id":"CU4nhIFXGRej"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**K-nearest Neighbors Regression in Python**  \n","\n","The Python code below predicts a bean's convex area from the bean's major and minor axis lengths."],"metadata":{"id":"5AQ4hRaUGVr4"}},{"cell_type":"code","source":["# Import needed packages for classification\n","from sklearn.neighbors import KNeighborsRegressor\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","# Import packages for visualization of results\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from matplotlib.colors import ListedColormap\n","\n","# Import packages for evaluation\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics"],"metadata":{"id":"sgFUzzCQGYAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read data, clean up names\n","\n","beans = pd.read_csv(\"https://raw.githubusercontent.com/mh2t/DS5110/main/data/Dry_Bean_Dataset.csv\")\n","print(beans.shape)\n","beans.describe()"],"metadata":{"id":"7-pGPDaLGaJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize model\n","beanKnnRegressor = KNeighborsRegressor(n_neighbors=5)\n","# Split data\n","X = beans[[\"MajorAxisLength\", \"MinorAxisLength\"]]\n","y = beans[[\"ConvexArea\"]]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"],"metadata":{"id":"hYpyUgDFGcnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scale data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)"],"metadata":{"id":"JaMTbngIGd-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit model and predict on test data\n","beanKnnRegressor.fit(X_train, np.ravel(y_train))\n","y_pred = beanKnnRegressor.predict(X_test)"],"metadata":{"id":"xz9LmkOiGfgB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the actual value vs. the predicted value\n","plt.scatter(x=y_test, y=y_pred)"],"metadata":{"id":"RM5PZt_uGg6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute metrics\n","print(metrics.mean_squared_error(y_pred, y_test))\n","print(metrics.r2_score(y_pred, y_test))"],"metadata":{"id":"Iwh7cTIEGiZZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Naive Bayes Classification with Python**\n","\n","Initializing the naive Bayes classifier (`NBModel = MultinomialNB()`) involves utilizing the described method. Text for the model requires `CountVectorizer(ngram_range = (1,2))` processing, counting single words and word pairs. The parameters for both can be found in the [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html). Fit the model (`NBModel.fit(X, y)`) after initialization, using trained vectorizer result (`X`) and corresponding class vector (`y`).  \n","\n","The Python code below builds a naive Bayes model that predicts whether a text message is spam or not (ham).\n","\n"],"metadata":{"id":"O4dV6c2xGujs"}},{"cell_type":"code","source":["# Import packages and functions\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB"],"metadata":{"id":"CrI943i-HXT8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read in the data and check.  Since the data is tab separated, pd.read_table is used.\n","# File does not include column headers so they are provided via names.\n","messages = pd.read_table('https://raw.githubusercontent.com/mh2t/DS5110/main/data/SMSSpamCollection.csv', names=['Class', 'Message'])\n","messages.head()"],"metadata":{"id":"PNdZEDEDHY0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split into testing and training sets\n","X_train, X_test, Y_train, Y_test = train_test_split(\n","    messages['Message'], messages['Class'], random_state=20220530\n",")"],"metadata":{"id":"r1sP_Ot0Hai6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count the words that appear in the messages\n","vectorizer = CountVectorizer(ngram_range=(1, 1))\n","vectorizer.fit(X_train)\n","# Uncomment the line below to see the words.\n","#vectorizer.vocabulary_"],"metadata":{"id":"WquglEMCHcGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count the words in the training set and store in a matrix\n","X_train_vectorized = vectorizer.transform(X_train)\n","X_train_vectorized"],"metadata":{"id":"BnFhkJ-vHdaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the model and fit with the training data\n","NBmodel = MultinomialNB()\n","NBmodel.fit(X_train_vectorized, Y_train)"],"metadata":{"id":"BHrkJ9AAHfvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions onto the training and testing sets.\n","trainPredictions = NBmodel.predict(vectorizer.transform(X_train))\n","testPredictions = NBmodel.predict(vectorizer.transform(X_test))"],"metadata":{"id":"6tghA67MHhOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How does the model work on the training set?\n","confusion_matrix(Y_train, trainPredictions)"],"metadata":{"id":"T49rQTSJHihT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display that in terms of correct porportions\n","confusion_matrix(Y_train, trainPredictions, normalize='true')"],"metadata":{"id":"4D867jMCHj3P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["99.7% of real messages are classified correctly.\n","Just over 3% of spam messages are thought to be real."],"metadata":{"id":"d8JsJh7gHmJ2"}},{"cell_type":"code","source":["# How does the model work on the test set?\n","confusion_matrix(Y_test, testPredictions, normalize='true')"],"metadata":{"id":"NOHJSJdmHmuX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["About 7.5% of spam messages are classified as real in the test data and only 0.4 % of real messages are classified as spam."],"metadata":{"id":"8ofELGCxHpvq"}},{"cell_type":"code","source":["# Predict some phrases. Add your own.\n","NBmodel.predict(\n","    vectorizer.transform(\n","        [\"Big sale today! Free cash.\",\n","        \"I'll be there in 5\"]))"],"metadata":{"id":"iTuFpDF1Hn8B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Support Vector Machine Classification in Python**  \n","\n","\n","Initializing a linear support vector machine classifier (`SVC(C = 10, kernel = 'linear')`) sets slope of hinge loss function to 10. The rest of the parameters and matching values can be found in [scikit-learn docs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). After, use `model.fit(X, y`) with input dataframe (`X`) and class vector (`y`). Scale `X` with `StandardScaler()` before fitting due to SVM's distance reliance.  \n","\n","The Python code below predicts a penguin's species based on a penguin's measurements using several kernels."],"metadata":{"id":"6TapI_4BHxXs"}},{"cell_type":"code","source":["# Load packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"qwoo9Vb_IWGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load and view data\n","penguins = sns.load_dataset('penguins')\n","penguins"],"metadata":{"id":"2Q7zBpeLIXg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove the penguins with missing data\n","penguinsClean = penguins[~penguins['body_mass_g'].isna()]"],"metadata":{"id":"sebW92z2IY0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Only use numeric values. Categorical values could be encoded as dummy variables.\n","\n","X = penguinsClean[\n","    ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n","]\n","Y = penguinsClean['species']\n","\n","# Split the data into training and testing sets.\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=20220621)\n","\n","# Scale the input variable because SVM is dependent on differences in scale for distances\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"],"metadata":{"id":"VZQzuhCGIbI2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Linear SVM**"],"metadata":{"id":"SKbMmTZiIdjG"}},{"cell_type":"code","source":["# Define and fit the model.\n","# Adjust C from 0.01 to 100 by changing the number of decimal places or zeros.\n","# C controls the slope of the hinge function. Larger values make misclassification less frequent.\n","\n","penguinsSVMlinear = svm.SVC(kernel='linear', C=0.01)\n","penguinsSVMlinear.fit(X_train_scaled, Y_train)"],"metadata":{"id":"jufm1l9tIfj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict for the test set\n","Y_pred = penguinsSVMlinear.predict(X_test_scaled)"],"metadata":{"id":"iFZYCKlUIhRM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the confusion matrix\n","confusion_matrix(Y_test, Y_pred)"],"metadata":{"id":"ogioDy-5IjFZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Radial Basis Function (RBF)**  \n","\n","\n"],"metadata":{"id":"7Fw33v1oIkqW"}},{"cell_type":"code","source":["# Adjust the number of decimal places in\n","# gamma (affects distance a point has influence, smaller value of gamma allow influence to spread more )\n","# and C\n","\n","penguinsSVMrbf = svm.SVC(kernel='rbf', C=10, gamma=0.01)\n","penguinsSVMrbf.fit(X_train_scaled, Y_train)"],"metadata":{"id":"T70QshLVIqch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict for the test set\n","Y_pred = penguinsSVMrbf.predict(X_test_scaled)"],"metadata":{"id":"0eEH5H6BIr_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the confusion matrix\n","confusion_matrix(Y_test, Y_pred)"],"metadata":{"id":"cehMA5IxIsXF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adjust the number of decimal places in C and change degree by steps of 1.\n","# Degree impacts the degree of the polynomial for the kernel.\n","\n","penguinsSVMpoly = svm.SVC(kernel='poly', C=0.1, degree=5)\n","penguinsSVMpoly.fit(X_train_scaled, Y_train)"],"metadata":{"id":"EK-Ufi9GItsv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict for the test set\n","Y_pred = penguinsSVMpoly.predict(X_test_scaled)"],"metadata":{"id":"qyZw7_ikIwh-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the confusion matrix\n","confusion_matrix(Y_test, Y_pred)"],"metadata":{"id":"NcMy0eEiIxs4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Accessing Information**\n"],"metadata":{"id":"rnrgpWnOIz_m"}},{"cell_type":"code","source":["# The number of support vectors for each class\n","penguinsSVMrbf.n_support_"],"metadata":{"id":"Iz4Ri4bJI2R8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Which instances in the training set are support vectors\n","penguinsSVMrbf.support_"],"metadata":{"id":"IebTjWweI3kE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The coefficients of the hyperplanes for each pair of classes in the form intercept = coefficient1*variable1 + coefficient2*variable2 + ...\n","penguinsSVMlinear.coef_"],"metadata":{"id":"bXBf0-XsI5TM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The intercept of the hyperplanes for each pair of classes.\n","penguinsSVMlinear.intercept_"],"metadata":{"id":"nyjCjCgEI6cQ"},"execution_count":null,"outputs":[]}]}