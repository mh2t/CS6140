{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Single-Layer Perceptron for Regression"
      ],
      "metadata": {
        "id": "cIQlPcEXRwGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94m8Po7g5ibJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SingleLayerPerceptronRegression:\n",
        "    def __init__(self):\n",
        "        self.weights = np.random.rand(2)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights[1:]) + self.weights[0]\n",
        "\n",
        "    def train(self, X, y, learning_rate=0.01, epochs=100):\n",
        "      for _ in range(epochs):\n",
        "        predictions = self.predict(X)\n",
        "        errors = y - predictions\n",
        "        weight_updates = np.dot(X.T, errors) * learning_rate\n",
        "        bias_update = np.sum(errors) * learning_rate\n",
        "\n",
        "        # Update weights and bias\n",
        "        self.weights[1:] += weight_updates\n",
        "        self.weights[0] += bias_update\n",
        "\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[2], [4], [6]])\n",
        "y = np.array([3, 6, 9])  # Example linear relationship: y = 1.5x\n",
        "model = SingleLayerPerceptronRegression()\n",
        "model.train(X, y)\n",
        "print(model.predict(np.array([8])))  # Should be close to 12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Single-Layer Perceptron for Classification"
      ],
      "metadata": {
        "id": "a3WUnH2aRysM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleLayerPerceptronClassification:\n",
        "    def __init__(self):\n",
        "        self.weights = np.random.rand(2)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(np.dot(X, self.weights[1:]) + self.weights[0] >= 0.0, 1, 0)\n",
        "\n",
        "    def train(self, X, y, learning_rate=0.01, epochs=100):\n",
        "        for _ in range(epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                update = learning_rate * (target - self.predict(xi))\n",
        "                self.weights[1:] += update * xi\n",
        "                self.weights[0] += update\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[0], [1], [2], [3]])\n",
        "y = np.array([0, 0, 1, 1])  # Simple binary classification\n",
        "model = SingleLayerPerceptronClassification()\n",
        "model.train(X, y)\n",
        "print(model.predict(np.array([1.5])))  # Should be 0\n",
        "print(model.predict(np.array([2.5])))  # Should be 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsPzeWZAR2wR",
        "outputId": "4c8b3543-c901-42ae-860d-b6d5c1af3e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Ensure reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(10,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate synthetic data for training\n",
        "X_train = np.random.random((1000, 10))  # 1000 samples, 10 features\n",
        "y_train = np.random.randint(2, size=(1000, 1))  # Binary targets (0 or 1)\n",
        "\n",
        "# Generate synthetic data for testing\n",
        "X_test = np.random.random((200, 10))  # 200 samples, 10 features\n",
        "y_test = np.random.randint(2, size=(200, 1))  # Binary targets (0 or 1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
        "\n",
        "# Make predictions on new data\n",
        "predictions = model.predict(X_test)\n",
        "# Interpret predictions as class labels\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Optionally, you might want to see some predictions\n",
        "for i in range(10):  # Just show 10 predictions for brevity\n",
        "    print(f\"Predicted: {predicted_classes[i][0]}, Actual: {y_test[i][0]}\")\n"
      ],
      "metadata": {
        "id": "G2Zy_iKjWiXF",
        "outputId": "e2266923-c0e2-4eba-ccf9-2e3d3066fc47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5270\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5590\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5490\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5570\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5600\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.5650\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5690\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5750\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5860\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5880\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.5300\n",
            "Test loss: 0.7045484185218811, Test accuracy: 0.5299999713897705\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Predicted: 1, Actual: 0\n",
            "Predicted: 1, Actual: 1\n",
            "Predicted: 1, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 1, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 1, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 1, Actual: 1\n"
          ]
        }
      ]
    }
  ]
}